{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from random import sample\n",
    "import multiprocessing\n",
    "from time import time\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = joblib.load('./mps_2017_tweets.pckle')\n",
    "\n",
    "all_sentences = []\n",
    " \n",
    "def extract_sentences(mps_tweets_df):\n",
    "    mps_tweets_df['author'] = mps_tweets_df['author'].apply(lambda x: x.lower())\n",
    "    mps_tweets_df['author'] = mps_tweets_df['author'].apply(lambda x: x.split()[0])\n",
    "\n",
    "    author_contents_mps_tweets_df = mps_tweets_df[['author', 'contents']].copy()\n",
    "\n",
    "    dict_of_mps = {k: v for k, v in author_contents_mps_tweets_df.groupby('author')['contents']}\n",
    "    new_dict_of_mps = {}\n",
    "\n",
    "    for k, v in dict_of_mps.items():\n",
    "        vals = []\n",
    "        for val in v:\n",
    "            tokeniser = TweetTokenizer()\n",
    "            tokens = tokeniser.tokenize(val)\n",
    "            filtered_sentence = [w for w in tokens if not w in stopwords.words()]\n",
    "            vals.append(filtered_sentence)\n",
    "        new_dict_of_mps[k] = vals\n",
    "\n",
    "    return new_dict_of_mps\n",
    "\n",
    "for dict_of_tweets in all_tweets[:-1]:\n",
    "    all_sentences.append(extract_sentences(pd.DataFrame.from_dict(dict_of_tweets['posts'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_to_sample = []\n",
    "for day in all_sentences:\n",
    "    for sentence in day.values():\n",
    "        sentences_to_sample += sentence\n",
    "        \n",
    "limit = len(sentences_to_sample)\n",
    "\n",
    "for sentence in range(0, limit):\n",
    "    temp = sample(sentences_to_sample[sentence], len(sentences_to_sample[sentence]))\n",
    "    sentences_to_sample += temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "\n",
    "w2v_model = Word2Vec(min_count=1,\n",
    "                     window=2,\n",
    "                     size=100,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)\n",
    "\n",
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences_to_sample, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences_to_sample, total_examples=w2v_model.corpus_count, epochs=50, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "w2v_model.init_sims(replace=True)\n",
    "\n",
    "w2v_model.save(\"w2v_model2018.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
